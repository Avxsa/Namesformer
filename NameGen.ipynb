{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "x6l1W4OLIr4a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjEsPRw84X1B",
        "outputId": "1a058a9a-96d2-44a0-c3bf-e6d429be284c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/235.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/235.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "X028_KGcIvNd"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset kurimas\n",
        "Pašalinamos visos nereikalingos raidės išskyrus mažasias."
      ],
      "metadata": {
        "id": "r7ar-f7ApmI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import unidecode\n",
        "\n",
        "def preprocess_name(name):\n",
        "    return unidecode.unidecode(name.lower())\n",
        "\n",
        "man_names = []\n",
        "woman_names = []\n",
        "\n",
        "for key in ['a', 'b', 'c', 'c-2', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "            'm', 'n', 'o', 'p', 'r', 's', 's-2', 't', 'u', 'v', 'z', 'z-2']:\n",
        "    url = f'https://vardai.vlkk.lt/sarasas/{key}/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    man_links = soup.find_all('a', class_='names_list__links names_list__links--man')\n",
        "    man_names += [preprocess_name(name.text) for name in man_links]\n",
        "\n",
        "    woman_links = soup.find_all('a', class_='names_list__links names_list__links--woman')\n",
        "    woman_names += [preprocess_name(name.text) for name in woman_links]\n",
        "\n",
        "pd.DataFrame(man_names, columns=['name']).to_csv('m_names.csv', index=False)\n",
        "pd.DataFrame(woman_names, columns=['name']).to_csv('w_names.csv', index=False)"
      ],
      "metadata": {
        "id": "VtVu_DZTcjDU"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NameDataset(Dataset):\n",
        "    def __init__(self, csv_file):\n",
        "        self.names = pd.read_csv(csv_file)['name'].values\n",
        "        self.chars = sorted(list(set(''.join(self.names) + ' ')))\n",
        "        self.char_to_int = {c: i for i, c in enumerate(self.chars)}\n",
        "        self.int_to_char = {i: c for c, i in self.char_to_int.items()}\n",
        "        self.vocab_size = len(self.chars)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.names[idx] + ' '\n",
        "        encoded_name = [self.char_to_int[char] for char in name]\n",
        "        return torch.tensor(encoded_name)"
      ],
      "metadata": {
        "id": "c1UtSHg-e15Q"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m_dataset = NameDataset('m_names.csv')\n",
        "w_dataset = NameDataset('w_names.csv')\n",
        "\n",
        "decoded_m_name = ''.join([m_dataset.int_to_char[idx.item()] for idx in m_dataset[0]])\n",
        "decoded_w_name = ''.join([w_dataset.int_to_char[idx.item()] for idx in w_dataset[0]])\n",
        "\n",
        "print(f'Man name: \"{decoded_m_name}\"')\n",
        "print(f'Woman name: \"{decoded_w_name}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yu7Z1GLVgKNl",
        "outputId": "aebf06a6-6249-4d25-8042-6173eb9790dd"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Man name: \"abas \"\n",
            "Woman name: \"abe \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datos paruošimas"
      ],
      "metadata": {
        "id": "s-nBL6JspQUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_collate(batch):\n",
        "    padded_seqs = pad_sequence(batch, batch_first=True, padding_value=0)\n",
        "    input_seq = padded_seqs[:, :-1]\n",
        "    target_seq = padded_seqs[:, 1:]\n",
        "    return input_seq, target_seq\n",
        "\n",
        "m_dataloader = DataLoader(m_dataset, batch_size=32, shuffle=True, collate_fn=pad_collate)\n",
        "w_dataloader = DataLoader(w_dataset, batch_size=32, shuffle=True, collate_fn=pad_collate)\n"
      ],
      "metadata": {
        "id": "pb5uS3o92cJV"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treniravimas bei pats modelio sukurimas\n",
        "Modelis yra įkeltas į arch.py (MinimalTransformer). Šis modelis skirtas, kurti vardus ir moterims ir vyrams. Yra du skirtingi encoderiai m_encoder - vyriškiems vardams, o w_encoder - moteriškiems, bet architektūra išlieka tapati. Kad nuspręsti dėl encoderio naudojamas parametras gender, kuris gali būti arba m, arba w."
      ],
      "metadata": {
        "id": "F8tnbzsun3Jl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from arch import MinimalTransformer\n",
        "from utilsforjupyter import train, sample\n",
        "\n",
        "model = MinimalTransformer(vocab_size=m_dataset.vocab_size, embed_size=128, num_heads=8, forward_expansion=4)\n",
        "\n",
        "print(\"Training on man names dataset:\")\n",
        "train(model, m_dataloader, gender='m', epochs=15)\n",
        "\n",
        "print(\"\\nTraining on woman names dataset:\")\n",
        "train(model, w_dataloader, gender='w', epochs=15)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsjFjrkA2lSs",
        "outputId": "0e2dcabb-f81d-4b8c-ef6e-fed47b8fb120",
        "collapsed": true
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on man names dataset:\n",
            "Epoch 1/15 (m), Loss: 1.2893228924964084\n",
            "Epoch 2/15 (m), Loss: 1.1716887546964914\n",
            "Epoch 3/15 (m), Loss: 1.1577868993617286\n",
            "Epoch 4/15 (m), Loss: 1.1501042980793095\n",
            "Epoch 5/15 (m), Loss: 1.1354533980700596\n",
            "Epoch 6/15 (m), Loss: 1.1337486707474576\n",
            "Epoch 7/15 (m), Loss: 1.1285725245791034\n",
            "Epoch 8/15 (m), Loss: 1.1258878274397417\n",
            "Epoch 9/15 (m), Loss: 1.125634959906586\n",
            "Epoch 10/15 (m), Loss: 1.1218698940986445\n",
            "Epoch 11/15 (m), Loss: 1.1129084633401602\n",
            "Epoch 12/15 (m), Loss: 1.1126101204186432\n",
            "Epoch 13/15 (m), Loss: 1.1088492481176517\n",
            "Epoch 14/15 (m), Loss: 1.1037366961644701\n",
            "Epoch 15/15 (m), Loss: 1.110900941466497\n",
            "\n",
            "Training on woman names dataset:\n",
            "Epoch 1/15 (w), Loss: 1.3816265746166831\n",
            "Epoch 2/15 (w), Loss: 1.1929793779115032\n",
            "Epoch 3/15 (w), Loss: 1.1792138142693311\n",
            "Epoch 4/15 (w), Loss: 1.1663570888060377\n",
            "Epoch 5/15 (w), Loss: 1.161831662170869\n",
            "Epoch 6/15 (w), Loss: 1.1620637052937557\n",
            "Epoch 7/15 (w), Loss: 1.154253229610902\n",
            "Epoch 8/15 (w), Loss: 1.1643975390527481\n",
            "Epoch 9/15 (w), Loss: 1.1539584505826908\n",
            "Epoch 10/15 (w), Loss: 1.1471322770405532\n",
            "Epoch 11/15 (w), Loss: 1.1468830565760906\n",
            "Epoch 12/15 (w), Loss: 1.152186505776599\n",
            "Epoch 13/15 (w), Loss: 1.1390290910140015\n",
            "Epoch 14/15 (w), Loss: 1.1405965578287167\n",
            "Epoch 15/15 (w), Loss: 1.1430010468439948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vardų generavimas\n",
        "Naudojantims sample funkcija iš utilsforjupyter.py. Ši funkcija pasinaudoja temperature logika, kuri parodo ant kiek AI yra įsitikines vardo tikslumu. Modelis naudojamas atspeti po raidę kiekviename varde, priklausnat nuo tikimybės."
      ],
      "metadata": {
        "id": "VNDoFdFgm4PU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample(\n",
        "    model,\n",
        "    m_dataset,\n",
        "    w_dataset,\n",
        "    start_str='a',\n",
        "    max_length=20,\n",
        "    num_names=5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYGXfjq-g3Y0",
        "outputId": "e8a6d008-9131-4a82-a6a4-5cb926954fa0"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confidence           Man Names                      Woman Names                   \n",
            "-------------------------------------------------------------------------------------\n",
            "Higher Confidence   \n",
            "                     airinas                        arime                         \n",
            "                     alivilas                       ailija                        \n",
            "                     adetanas                       aulija                        \n",
            "                     ailejus                        alinone                       \n",
            "                     alekonas                       augija                        \n",
            "\n",
            "More Creative       \n",
            "                     aitanrabas                     atiuedijogna                  \n",
            "                     agmmaktas                      almja                         \n",
            "                     aurntaneodvavigugane           auzkinyza                     \n",
            "                     amatylgonileridagari           antinana                      \n",
            "                     aldiamyus                      agada                         \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Išsaugojam modelį"
      ],
      "metadata": {
        "id": "YWaZavAymroU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'namesformer_model.pt')"
      ],
      "metadata": {
        "id": "XmKgrH9saTOk"
      },
      "execution_count": 151,
      "outputs": []
    }
  ]
}